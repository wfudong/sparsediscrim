If we apply DQDA or SDQDA, do we improve the classification performance?

Add pi_k to the classifier to DLDA
Add option to set prior probabilities DLDA.
	'prior = 1' indicates equal probabilities.

Add pi_k to the classifier to DQDA
Add option to set prior probabilities DQDA.
	'prior = 1' indicates equal probabilities.

Add pi_k to the classifier to SDLDA
Add option to set prior probabilities SDLDA.
	'prior = 1' indicates equal probabilities.

Add pi_k to the classifier to SDQDA
Add option to set prior probabilities SDQDA.
	'prior = 1' indicates equal probabilities.


A very useful set of notes is given here:
http://www.prip.tuwien.ac.at/teaching/ws/StME/apponly.pdf

They mention a paper in Pattern Recognition (2001) that does the same thing but in the equal cov matrix case for dimension reduction.
	The paper is by Yu and Yang (2001) and entitled "A Direct LDA Algorithm for High-Dimensional Data â€“ with Application to Face Recognition"
	Unbeknownst to Srivastava, this had already been done.
	As far as I am know, Srivastava's method is the same as this one.